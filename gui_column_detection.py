"""åˆ—æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹GUIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€train_yolov12_column.pyã§å­¦ç¿’ã—ãŸåˆ—æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚
ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ—ã‚’æ¤œå‡ºã—ã€çµæœã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
"""

import base64
import io
import json
from pathlib import Path

import gradio as gr
import torch
from PIL import Image, ImageDraw, ImageFont
from yolov12.ultralytics import YOLO

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š (â˜…ã”è‡ªèº«ã®ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„) ---
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆæœ€æ–°ã®å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰è‡ªå‹•æ¤œå‡ºã‚’è©¦ã¿ã‚‹ï¼‰
DEFAULT_MODEL_PATH = None  # Noneã®å ´åˆã¯æœ€æ–°ã®å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰è‡ªå‹•æ¤œå‡º
CONF_THRESHOLD = 0.25
# --- è¨­å®šã“ã“ã¾ã§ ---

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL = None


def find_latest_model() -> Path | None:
    """æœ€æ–°ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢"""
    experiments_dir = Path("experiments/yolov12_column")
    if not experiments_dir.exists():
        return None

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    model_dirs = []
    for exp_dir in experiments_dir.iterdir():
        if exp_dir.is_dir():
            weights_path = exp_dir / "weights" / "best.pt"
            if weights_path.exists():
                model_dirs.append((exp_dir.name, weights_path))

    if not model_dirs:
        return None

    # æœ€æ–°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ï¼‰
    model_dirs.sort(key=lambda x: x[0], reverse=True)
    return model_dirs[0][1]


def load_model(model_path: str | None = None):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    global MODEL

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    if model_path is None or model_path == "":
        if DEFAULT_MODEL_PATH and Path(DEFAULT_MODEL_PATH).exists():
            model_path = DEFAULT_MODEL_PATH
        else:
            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
            auto_path = find_latest_model()
            if auto_path:
                model_path = str(auto_path)
            else:
                gr.Warning("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚experiments/yolov12_column/ ä»¥ä¸‹ã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                MODEL = None
                return

    if not Path(model_path).exists():
        gr.Warning(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        MODEL = None
        return

    try:
        MODEL = YOLO(model_path).to(DEVICE)
        gr.Info(f"åˆ—æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {model_path}")
    except Exception as e:
        gr.Error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        MODEL = None


def perform_yolo_detection(image: Image.Image, confidence_threshold: float) -> list[dict]:
    """YOLOãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦åˆ—ã‚’æ¤œå‡º"""
    if MODEL is None:
        return []

    try:
        results = MODEL.predict(image, conf=confidence_threshold, verbose=False)
        detections = []

        if results and results[0].boxes:
            for box in results[0].boxes.data.cpu().numpy():
                x1, y1, x2, y2, confidence, class_id = box
                detections.append(
                    {
                        "bbox": [float(x1), float(y1), float(x2), float(y2)],
                        "confidence": float(confidence),
                        "class_id": int(class_id),
                    }
                )
        return detections
    except Exception as e:
        print(f"æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []


def draw_boxes(image: Image.Image, detections: list[dict], color: str = "red") -> Image.Image:
    """æ¤œå‡ºçµæœã‚’ç”»åƒã«æç”»"""
    draw_image = image.copy()
    draw = ImageDraw.Draw(draw_image)

    try:
        font = ImageFont.truetype("assets/fonts/fonts-japanese-gothic.ttf", 40)
    except OSError:
        font = ImageFont.load_default()

    for i, det in enumerate(detections):
        x1, y1, x2, y2 = det["bbox"]
        confidence = det["confidence"]

        # çŸ©å½¢ã‚’æç”»
        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        # ä¿¡é ¼åº¦ã¨åˆ—ç•ªå·ã‚’è¡¨ç¤º
        label_text = f"Col{i+1}: {confidence:.2f}"
        text_x, text_y = x2 + 5, y1
        draw.text((text_x, text_y), label_text, fill="black", font=font)

    return draw_image


def visualize_json_data(json_string: str, base_image: Image.Image) -> Image.Image | None:
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€ç”»åƒã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦çŸ©å½¢ã‚’æç”»ã™ã‚‹"""
    if not json_string.strip() or not base_image:
        return None

    try:
        data = json.loads(json_string)
    except json.JSONDecodeError:
        gr.Warning("JSONã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None

    draw_image = base_image.copy()
    image_w, image_h = base_image.size
    draw = ImageDraw.Draw(draw_image)

    try:
        font_size = max(15, int(image_h / 60))
        font = ImageFont.truetype("assets/fonts/fonts-japanese-gothic.ttf", font_size)
    except OSError:
        font = ImageFont.load_default()

    # æ–°ã—ã„JSONå½¢å¼ã‹ã‚‰ç”»åƒã‚µã‚¤ã‚ºã‚’æŠ½å‡º
    json_w, json_h = None, None
    if "imginfo" in data and isinstance(data["imginfo"], dict):
        json_w = data["imginfo"].get("img_width")
        json_h = data["imginfo"].get("img_height")

    scale_x, scale_y = (image_w / json_w, image_h / json_h) if json_w and json_h else (1.0, 1.0)
    if scale_x == 1.0 and scale_y == 1.0:
        gr.Info("JSONã«'imginfo'ã¨'img_width'/'img_height'ã‚­ãƒ¼ãŒãªã„ã‹ã€ç”»åƒã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚")

    # "contents"ã‚­ãƒ¼ã®å­˜åœ¨ã‚’ç¢ºèª
    if "contents" not in data or not isinstance(data["contents"], list):
        gr.Warning("JSONã«'contents'ã‚­ãƒ¼ãŒãªã„ã‹ã€ãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None

    # "contents"å†…ã®å„çŸ©å½¢æƒ…å ±ã‚’å‡¦ç†
    for i, content in enumerate(data["contents"]):
        if not isinstance(content, list) or len(content) < 4:
            continue

        # åˆ—æ¤œå‡ºã®å ´åˆã¯ã€x1, y1, x2, y2ã®4è¦ç´ ã®ã¿ã‚’æƒ³å®š
        if len(content) >= 4:
            x1, y1, x2, y2 = content[:4]

            if not all(isinstance(v, (int, float)) for v in [x1, y1, x2, y2]):
                continue

            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é©ç”¨
            x, y, w, h = x1 * scale_x, y1 * scale_y, (x2 - x1) * scale_x, (y2 - y1) * scale_y

            # çŸ©å½¢ã‚’æç”»
            draw.rectangle([x, y, x + w, y + h], outline="green", width=3)

            # åˆ—ç•ªå·ã‚’è¡¨ç¤º
            label_text = f"Col{i+1}"
            try:
                bbox = draw.textbbox((0, 0), label_text, font=font)
                text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]
            except AttributeError:  # å¤ã„Pillowãƒãƒ¼ã‚¸ãƒ§ãƒ³ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                text_w, text_h = draw.textsize(label_text, font=font)

            draw_x = x + (w - text_w) // 2
            draw_y = y + 5
            draw.text((draw_x, draw_y), label_text, fill="blue", font=font)

    return draw_image


def resize_image(image: Image.Image, height: int = 1280) -> Image.Image:
    """ç”»åƒã‚’æŒ‡å®šã—ãŸé«˜ã•ã«ãƒªã‚µã‚¤ã‚ºï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒï¼‰"""
    if image is None:
        return None
    return image.resize((int(height * image.width / image.height), height), Image.Resampling.LANCZOS)


def predict(
    uploaded_image: Image.Image,
    json_string: str,
    confidence_threshold: float,
    model_path: str | None,
):
    """æ¨è«–ã¨JSONå¯è¦–åŒ–ã‚’åŒæ™‚ã«å®Ÿè¡Œã™ã‚‹"""
    # ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯å†è©¦è¡Œ
    if MODEL is None:
        if model_path:
            load_model(model_path)
        if MODEL is None:
            gr.Warning("ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            return None, None, None, gr.update(visible=False), None, gr.update(visible=False)

    if uploaded_image is None:
        gr.Info("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return None, None, None, gr.update(visible=False), None, gr.update(visible=False)

    image = uploaded_image.convert("RGB")

    # åˆ—æ¤œå‡ºã‚’å®Ÿè¡Œ
    detections = perform_yolo_detection(image, confidence_threshold)

    # æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–
    pred_img = draw_boxes(image.copy(), detections, color="red")

    # JSONå¯è¦–åŒ–
    json_vis_img = visualize_json_data(json_string, image.copy())
    json_zoom_visible = gr.update(visible=True) if json_vis_img is not None else gr.update(visible=False)

    # æ¤œå‡ºçµæœã®ã‚µãƒãƒªãƒ¼
    summary_text = f"æ¤œå‡ºã•ã‚ŒãŸåˆ—æ•°: {len(detections)}\n\n"
    for i, det in enumerate(detections):
        x1, y1, x2, y2 = det["bbox"]
        confidence = det["confidence"]
        summary_text += f"åˆ—{i+1}: ä¿¡é ¼åº¦={confidence:.3f}, åº§æ¨™=({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\n"

    return (
        resize_image(pred_img),
        resize_image(json_vis_img) if json_vis_img else None,
        pred_img,
        gr.update(visible=True),
        json_vis_img,
        json_zoom_visible,
        summary_text,
    )


def open_in_new_tab(img):
    """ç”»åƒã‚’æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããŸã‚ã®ãƒ‡ãƒ¼ã‚¿URIã‚’ç”Ÿæˆ"""
    if not isinstance(img, Image.Image):
        return ""
    buffer = io.BytesIO()
    img.save(buffer, format="PNG")
    img_str = base64.b64encode(buffer.getvalue()).decode("utf-8")
    return f"data:image/png;base64,{img_str}"


def create_ui():
    """Gradioã®UIã‚’æ§‹ç¯‰ã™ã‚‹"""
    open_tab_js = """
    (uri) => {
        if (!uri) { return; }
        const newWindow = window.open('', '_blank');
        if (newWindow) {
            newWindow.document.write(`<html><head><title>æ‹¡å¤§è¡¨ç¤º</title><style>body { margin: 0; background-color: #f0f0f0; display: flex; justify-content: center; align-items: center; min-height: 100vh; } img { max-width: 100%; max-height: 100vh; }</style></head><body><img src="${uri}"></body></html>`);
            newWindow.document.close();
        } else { alert('ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚'); }
    }
    """

    with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue")) as demo:
        gr.Markdown("# YOLOv12 åˆ—æ¤œå‡ºãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«")
        gr.Markdown("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ—æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã§åˆ—ã‚’æ¤œå‡ºã—ã¾ã™ã€‚")

        full_pred_img_state = gr.State()
        full_json_img_state = gr.State()
        data_uri_state = gr.Textbox(visible=False)

        with gr.Row():
            with gr.Column(scale=2):
                image_input = gr.Image(type="pil", label="ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
                json_input = gr.Textbox(
                    label="å¯è¦–åŒ–ã™ã‚‹JSONãƒ‡ãƒ¼ã‚¿ã‚’è²¼ã‚Šä»˜ã‘ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    lines=5,
                    placeholder='{"contents": [[x1, y1, x2, y2], ...], "imginfo": {"img_width": 1000, "img_height": 2000}}',
                )
                run_button = gr.Button("æ¨è«–å®Ÿè¡Œ", variant="primary")

            with gr.Column(scale=1):
                with gr.Accordion("æ¨è«–è¨­å®š", open=True):
                    model_path_input = gr.Textbox(
                        label="ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹",
                        placeholder="experiments/yolov12_column/YYYYMMDD_HHMMSS/weights/best.pt",
                        value="",
                        info="ç©ºæ¬„ã®å ´åˆã¯æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºã—ã¾ã™",
                    )
                    confidence_slider = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=CONF_THRESHOLD,
                        step=0.01,
                        label="ä¿¡é ¼åº¦ã—ãã„å€¤",
                        info="å€¤ãŒä½ã„ã»ã©ã€ã‚ˆã‚Šå¤šãã®åˆ—ãŒæ¤œå‡ºã•ã‚Œã¾ã™",
                    )

        gr.Markdown("---")
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### äºˆæ¸¬çµæœï¼ˆAIï¼‰")
                output_pred = gr.Image(label="Prediction (Red)", type="pil")
                zoom_button = gr.Button("ğŸ” äºˆæ¸¬çµæœã‚’æ‹¡å¤§", visible=False)

            with gr.Column(scale=1):
                gr.Markdown("### å¯è¦–åŒ–çµæœï¼ˆJSONï¼‰")
                output_json_vis = gr.Image(label="Visualization from JSON (Green)", type="pil")
                json_zoom_button = gr.Button("ğŸ” å¯è¦–åŒ–çµæœã‚’æ‹¡å¤§", visible=False)

            with gr.Column(scale=1):
                gr.Markdown("### æ¤œå‡ºçµæœã‚µãƒãƒªãƒ¼")
                output_summary = gr.Textbox(label="æ¤œå‡ºã•ã‚ŒãŸåˆ—ã®æƒ…å ±", lines=15, interactive=False)

        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        demo.load(load_model, inputs=[model_path_input], outputs=[])

        # æ¨è«–å®Ÿè¡Œ
        run_button.click(
            fn=predict,
            inputs=[image_input, json_input, confidence_slider, model_path_input],
            outputs=[
                output_pred,
                output_json_vis,
                full_pred_img_state,
                zoom_button,
                full_json_img_state,
                json_zoom_button,
                output_summary,
            ],
        )

        # æ‹¡å¤§è¡¨ç¤º
        zoom_button.click(fn=open_in_new_tab, inputs=[full_pred_img_state], outputs=[data_uri_state]).then(
            None, inputs=[data_uri_state], js=open_tab_js
        )
        json_zoom_button.click(fn=open_in_new_tab, inputs=[full_json_img_state], outputs=[data_uri_state]).then(
            None, inputs=[data_uri_state], js=open_tab_js
        )

    return demo


if __name__ == "__main__":
    app = create_ui()
    app.launch()

