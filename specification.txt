---

# くずし字ビジョンプロジェクト ドキュメント

## 1. プロジェクト概要
本プロジェクトは、日本古典籍の画像から文字情報（くずし字）を正確に抽出するOCRシステムの構築を目的としています。最終出力は、各ページ画像から抽出された文字列となります。主な処理は、入力画像の前処理、列単位（短冊状）への切り出し、文字位置・コードの検出、Unicodeから文字への変換、さらに言語モデル（LLM）による評価・補正となります。なお、パッケージ管理にはRye、実装にはPyTorchとAccelerateを採用し、高速かつ効率的なモデル運用を実現します。

## 2. タスク定義・処理フロー
### 2.1. 全体タスク
1. **列単位の短冊状切り出し**
   - 1ページの画像から、文字のある列を上から下まで探索し、短冊状に切り出す
   - 切り出しには、既存のYOLOやMobileNetなどの高速物体検出モデルの利用、もしくはアノテーション情報から新たに列境界を推定するモデルの設計を検討
   - ページ上部・下部からの探索により、通常の列はもちろん、途中で2列にまたがる部分は個別に分割する

2. **文字位置・コード抽出**
   - 短冊状に切り出された各列画像から、各文字のバウンディングボックス（x0, y0, x1, y1）およびUnicodeコードを抽出

3. **文字コードの変換と補正**
   - 抽出されたUnicodeコードを、実際の文字へ変換
   - 得られた文字列をLLM（言語モデル）により評価し、誤認識や文脈上の不整合を補正

4. **最終出力**
   - 補正済み文字列を出力

### 2.2. 各モジュールの概要
- **短冊状切り出しモジュール**
  - 入力画像から列領域を検出し、各列画像（短冊状画像）として抽出
  - トレーニングデータは、1ページ画像の文字位置アノテーション（例: `[ページID]_coordinate.csv`）から自動生成

- **文字位置・コード抽出モジュール**
  - 物体検出またはセマンティックセグメンテーション手法により、各文字の位置情報とUnicodeコードを検出

- **LLM補正モジュール**
  - 変換された文字列に対して、言語モデルを用いて文脈補正を実施し、最終的なテキストを生成

---

## 3. データセット仕様
### 3.1. 生データ（data/raw）
- **構成例**:
  - 各文書（ページ）はディレクトリ単位で管理
  - 例: `kuzushiji-vision/data/raw/dataset/[ページID]/`
    - `[ページID]_coordinate.csv`  
      *（※「coordunate」ではなく「coordinate」が正しいスペルです）*  
      各文字の位置、Unicode、ブロックID、サイズなどの詳細情報を記載
    - `images/`  
      １ページ全体の画像（例: `[ページID]_[画像ID].jpg`）
    - `characters/`  
      Unicodeごとに1文字をクロップした画像を管理  
      例: `characters/[UnicodeID]/[UnicodeID]_[ページID]_[画像ID]_X[X位置]_Y[Y位置].jpg`

### 3.2. 前処理済みデータ（data/processed）
- **column_images/**  
  短冊状に切り出した各列画像  
  例: `kuzushiji-vision/data/processed/column_images/[ページID]/[ページID]_[画像ID]_column_001.jpg`

---

## 4. モデルアーキテクチャと実装
### 4.1. 利用技術
- **パッケージ管理**: Rye  
- **実装フレームワーク**: PyTorch, Accelerate

### 4.2. モジュール別概要
- **column Extraction（短冊状切り出し）**
  - 役割: ページ画像から文字列を検出・切り出し
  - 実装: PyTorch＋Accelerateを利用したモデル（既存モデルの転用または新規設計検討）
  
- **Character Detection（文字位置・コード抽出）**
  - 役割: 各列画像から文字ごとのバウンディングボックスとUnicodeを検出
  - 実装: PyTorch＋Accelerateで構築

- **LLM Correction（言語モデルによる補正）**
  - 役割: 変換後の文字列に対し、言語モデルを用いて誤認識・文脈不整合の補正を実施
  - 実装: 適宜ライブラリ（例: HuggingFace Transformers等）を利用

---

## 5. トレーニング戦略と評価指標
### 5.1. トレーニング戦略
- **データ拡張**
  - ノイズ付加、明度・コントラスト調整、色相変更等により、学習データの多様性を確保し、汎化性能を向上
- **損失関数の改良**
  - Focal Loss（クラス不均衡対応）
  - Contrastive Loss（特徴空間の分離促進）
  - クロスエントロピー損失（文字列変換およびLLM補正の最適化）
- **正則化**
  - Dropout、Label Smoothingなどで過学習を抑制
- **アンサンブル学習**
  - 複数モデル（例: CNN＋Transformerハイブリッド）の統合により精度向上を目指す

### 5.2. 評価指標
- **文字位置の精度**: IoU（Intersection over Union）を用いて、予測されたバウンディングボックスと正解との重なりを評価
- **文字コードの精度**: 正解率（Accuracy）による評価
- **列切り出しの精度**: 列境界検出の正確性（上部・下部探索、2列混在部分の分割）の定量評価

---

## 6. ディレクトリ構造
以下は、Ryeによるパッケージ管理、PyTorch＋Accelerate実装、各モジュール・実験結果管理を含むディレクトリ構造の例です。

```markdown
kuzushiji-vision/
├── config/                         # モデル構造、訓練パラメータ、推論設定（YAML管理）
│   ├── model/                      # モデル構造設定
│   ├── training/                   # 訓練パラメータ設定
│   └── inference/                  # 推論設定
├── data/
│   ├── raw/                       # 生データ（原本画像、アノテーション）
│   │   └── dataset/               # 提供されたくずし字画像
│   │       ├─ [ページID]/         # 文書IDごとに分けられた画像
│   │       │  ├─ [ページID]_coordinate.csv  # 文字位置アノテーション（注意: "coordinate"が正しい）
│   │       │  ├─ characters/        # Unicodeごとにクロップした1文字画像
│   │       │  │   ├─ [UnicodeID]/
│   │       │  │   │  ├─ [UnicodeID]_[ページID]_[画像ID]_X[X位置]_Y[Y位置].jpg
│   │       │  │   │  └── ...
│   │       │  │   └── ...
│   │       │  └─ images/           # １ページ全体の画像
│   │       │      ├─ [ページID]_[画像ID].jpg
│   │       │      └── ...
│   │       └── ...
│   └── processed/                  # 前処理済みデータ（例：短冊状に切り出した列画像）
│       ├── column_images/            # 短冊状切り出し後の列画像
│       │   └── [ページID]/
│       │       ├── [ページID]_[画像ID]_column_001.jpg
│       │       └── ...
│       └── ...
├── models/
│   ├── column_extraction/            # 短冊状切り出し（列検出）モデル関連
│   │   ├── model.py              # PyTorchとAccelerate実装
│   │   └── README.md
│   ├── character_detection/        # 文字位置・コード抽出モデル関連
│   │   ├── model.py              # PyTorchとAccelerate実装
│   │   └── README.md
│   └── llm_correction/             # 言語モデルによる評価・補正モジュール
│       ├── model.py
│       └── README.md
├── experiments/                    # 実験結果保存用ディレクトリ
│   ├── 202501010000/               # 実験ごとのフォルダ（タイムスタンプ付き）
│   │   ├── config.yaml             # 実験設定
│   │   ├── logs/                   # TensorBoard/W&Bログ
│   │   ├── checkpoints/            # モデルチェックポイント
│   │   └── evaluation/             # 評価結果
│   └── ...
├── trainer/                        # 訓練関連モジュール
│   ├── train_column_extraction.py    # 列検出モデルの訓練
│   ├── train_character_detection.py# 文字検出モデルの訓練
│   └── train_llm_correction.py     # LLM補正モジュールの訓練
├── scripts/                        # 各種実行スクリプト
│   ├── data_preprocessing.py       # データ前処理（短冊状切り出し含む）
│   ├── run_pipeline.sh             # 全体パイプライン実行スクリプト
│   └── evaluation.py               # モデル評価用スクリプト
├── notebooks/                      # 試作用ノートブック
│   ├── plot_column_extraction.ipynb  # 列切り出し結果の可視化
│   ├── plot_character_detection.ipynb  # 文字検出結果の可視化
│   └── plot_llm_correction.ipynb   # LLM補正結果の可視化
├── docs/                           # プロジェクト関連ドキュメント
│   ├── project_documentation.md    # 全体設計・仕様書
│   └── design_overview.md          # モデル設計の概要
├── pyproject.toml                  # Ryeによるパッケージ管理設定ファイル
├── rye.lock                        # Ryeのロックファイル
└── README.md                       # プロジェクト概要、セットアップ手順（PyTorch, Accelerate依存）
```

---

## 7. 今後の課題と拡張ポイント
- **ユーティリティ関数管理**: 共通ライブラリ（例: `utils/` ディレクトリ）の整備によるコード再利用性向上
- **テスト環境の構築**: `tests/` ディレクトリを追加し、単体テスト・統合テストの自動化を実施
- **ドキュメント整備**: `CHANGELOG.md`、`CONTRIBUTING.md`、およびライセンスファイル（`LICENSE`）の追加
- **マルチモーダル学習**: 画像特徴と文脈情報の統合による認識精度のさらなる向上

---

## 8. まとめ
本ドキュメントでは、くずし字ビジョンプロジェクトの全体像、各タスク（列抽出、文字検出、LLM補正）の処理フロー、使用する技術（Rye, PyTorch, Accelerate）およびディレクトリ構造を包括的に整理しました。各モジュールの独立性を確保しつつ、実験結果の管理や環境構築を容易にする設計としています。今後は、各モジュールのプロトタイプ実装と評価を通じて、実運用に向けた最適化を進めていきます。

---
