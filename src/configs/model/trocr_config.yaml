# TrOCR Configuration File
# ViT Encoder + RoBERTa Decoder for Japanese Kuzushiji OCR

# Data Configuration
data:
  csv_path: "data/processed_v2/column_info.csv"
  image_root: "data/processed_v2/column_images"
  decoder_path: "experiments/pretrain_language_model/roberta-small-japanese-aozora-char/20250530_034458/checkpoint-200000"
  
  # Data splits
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  
  # Data processing
  image_size: [1024, 64]  # [height, width] - column images are tall and narrow
  max_length: 128
  
# Model Configuration
model:
  # ViT Encoder
  encoder:
    image_size: [1024, 64]  # Column images are tall and narrow
    patch_size: [16, 16]
    num_channels: 3
    hidden_size: 768
    num_hidden_layers: 12
    num_attention_heads: 12
    intermediate_size: 3072
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
  
  # RoBERTa Decoder (loaded from pre-trained checkpoint)
  decoder:
    path: "experiments/pretrain_language_model/roberta-small-japanese-aozora-char/20250530_034458/checkpoint-200000"
    # Configuration will be loaded from the checkpoint
    
# Training Configuration
training:
  # Optimization
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_steps: 1000
  max_epochs: 50
  
  # Data loading
  batch_size: 8
  num_workers: 4
  
  # Hardware
  gpus: 1
  precision: "16-mixed"  # or "32", "bf16-mixed"
  
  # Validation
  val_check_interval: 0.5  # Check validation every half epoch
  
  # Early stopping
  patience: 10
  
  # Gradient clipping
  gradient_clip_val: 1.0

# Output Configuration
output:
  experiment_name: "trocr_vit_roberta"
  output_dir: "experiments/trocr"
  
  # Checkpointing
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"
  
  # Logging
  log_every_n_steps: 50

# Inference Configuration
inference:
  max_length: 128
  num_beams: 4
  early_stopping: true
  
# Evaluation Configuration
evaluation:
  metrics:
    - "character_error_rate"
    - "word_error_rate"
    - "exact_match"
  
  # Sample evaluation during validation
  eval_samples_per_batch: 5
