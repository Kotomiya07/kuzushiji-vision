# Updated config/model/character_detection.yaml (for timm scheduler)
seed: 42 # Global random seed

model:
  name: "character_detection"
  # type: "vision_transformer" # 既存モデルを使う場合
  type: "csa_vit" # 新しいCSA-ViTモデルを使う場合
  backbone: "google/vit-base-patch16-384"  # ViTConfigの初期化や事前学習重みロードの参考に使う可能性あり
  input_size: [192, None]  # Resize to 192xN (variable width)
  patch_size: 16
  num_channels: 3 # ViTConfig用に追加
  num_heads: 12 # ViT-Baseのデフォルト (Self-Attention用)
  num_layers: 12
  hidden_size: 768 # ViT-Baseのデフォルト
  dropout: 0.1
  attention_dropout: 0.1 # Self-Attention用
  layer_norm_eps: 1e-12 # ViTConfig用に追加 (ViTのデフォルト値)
  num_classes: 4328  # Number of Kuzushiji classes (デコーダで使用)

  # --- CSA-ViT 固有設定 ---
  decoder_type: "ctc" # "ctc" or "transformer"
  # 構造適応モジュール設定
  use_structure_module_indices: [0, 1, 2] # 例: 最初の3層で使用
  structure_module_type: "cnn" # "cnn" or "gat" or null
  # CNNブランチ用設定 (structure_module_typeが'cnn'の場合)
  structure_cnn_kernel_size: 3
  structure_cnn_use_bn: true
  # GATブランチ用設定 (structure_module_typeが'gat'の場合)
  gat_heads: 4             # GATのヘッド数
  gat_dropout: 0.1         # GATのドロップアウト率
  gat_add_self_loops: true # GATで自己ループを追加するか

  # --- Transformer Decoder 設定 (decoder_typeが'transformer'の場合) ---
  decoder_layers: 6          # デコーダの層数 (例: エンコーダの半分)
  decoder_ffn_dim: 3072      # デコーダFFNの中間層次元 (例: hidden_size * 4)
  max_target_length: 100     # デコーダが扱う最大ターゲットシーケンス長 (位置エンコーディング用)
  inference_strategy: "greedy" # 推論時のデコード戦略 ("greedy" or "beam")
  beam_size: 5               # Beam Search のビームサイズ (inference_strategyが'beam'の場合)
  length_penalty_alpha: 0.7  # Beam Search の Length Normalization パラメータ (0で無効)
  # decoder_heads は num_heads を流用
  # decoder_dropout は dropout を流用

  # --- 文脈統合モジュール設定 ---
  use_context_module_indices: [9, 10, 11] # 例: 最後の3層で使用
  context_embedding_dim: 256 # 文脈埋め込みの次元 (外部から与えられる想定)
  layout_embedding_dim: 128 # レイアウト埋め込みの次元 (外部から与えられる想定)
  cross_attention_heads: 12 # Cross-Attentionのヘッド数 (num_headsと同じか別の値)
  cross_attention_dropout: 0.1 # Cross-Attentionのドロップアウト率
  # --- CSA-ViT 固有設定ここまで ---

  # 検出/後処理関連設定 (既存のものを流用)
  confidence_threshold: 0.5  # Detection score threshold
  nms_threshold: 0.5  # NMS IoU threshold
  # IoU threshold settings for detection loss calculation
  dynamic_iou_threshold: false # Use dynamic IoU threshold adjustment?
  fixed_iou_threshold: 0.5   # Fixed IoU threshold if dynamic_iou_threshold is false
  dynamic_iou_params:        # Parameters for dynamic adjustment (if enabled)
    start: 0.3             # Starting IoU threshold
    end: 0.5               # Ending IoU threshold
    epochs: 50             # Number of epochs to reach the end threshold

training:
  batch_size: 8
  learning_rate: 0.0001 # Initial learning rate for optimizer
  optimizer: "adamW"
  weight_decay: 0.05
  num_workers: 4 # Number of data loader workers
  early_stopping_patience: 10 # Patience for early stopping
  scheduler:
    # Settings for timm.scheduler.CosineLRScheduler
    # type: "timm_cosine" # Optional: Indicate scheduler type
    t_initial: 200      # Corresponds to total_epochs (since t_in_epochs=True)
    lr_min: 1e-6        # Minimum learning rate (formerly eta_min)
    warmup_t: 5         # Warmup epochs (formerly warmup_epochs)
    warmup_lr_init: 1e-7 # Initial learning rate during warmup

augmentation:
  horizontal_flip: false
  vertical_flip: false
  rotation: [-10, 10]
  scale: [0.9, 1.1]
  brightness: 0.1
  contrast: 0.1
  gaussian_noise: 0.05
  random_erase: 0.1

data:
  # Paths to annotation files
  train_annotation: "data/column_dataset/train/train_column_info.csv"
  val_annotation: "data/column_dataset/val/val_column_info.csv"
  test_annotation: "data/column_dataset/test/test_column_info.csv"
  # Paths to image directories
  train_image_dir: "data/column_dataset/train/images/"
  val_image_dir: "data/column_dataset/val/images/"
  test_image_dir: "data/column_dataset/test/images/"
  # Unicode dictionary for Kuzushiji characters
  unicode_dict: "data/column_dataset/unicode_to_id.json"

evaluation:
  iou_threshold: 0.5 # IoU threshold for mAP and accuracy calculation
  num_visualizations: 5 # Number of validation samples to visualize

# Experiment tracking and saving settings
experiment:
  save_dir: "experiments/character_detection/%Y%m%d_%H%M%S"
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  eval_dir: "evaluation"

# Wandb settings
wandb:
  project: "kuzushiji-character-detection" # Wandb project name
  entity: null # Optional: Wandb entity (username or team name)
  name_format: "%Y%m%d_%H%M%S" # Optional: Wandb run name format
