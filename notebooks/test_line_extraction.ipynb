{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Extraction モデルのテスト\n",
    "\n",
    "このnotebookでは、学習済みのline extractionモデルの性能評価と結果の可視化を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/project/kuzushiji-vision-lightning\n",
    "\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "# 警告を無視\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# GPUが利用可能な場合は使用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 実験設定の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験ディレクトリの設定\n",
    "experiment_dir = \"experiments/line_extraction/20250501_213827\"\n",
    "model_path = os.path.join(experiment_dir, \"weights/best.pt\")\n",
    "config_path = os.path.join(experiment_dir, \"config.yaml\")\n",
    "\n",
    "\n",
    "# 設定ファイルの読み込み\n",
    "def load_yaml(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "config = load_yaml(config_path)\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Model path: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理用の関数\n",
    "def preprocess_image(image_path, input_size=(640, 640)):\n",
    "    \"\"\"画像の前処理を行う\n",
    "\n",
    "    Args:\n",
    "        image_path (str): 画像ファイルのパス\n",
    "        input_size (tuple): 入力サイズ\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 前処理済みの画像テンソル\n",
    "        tuple: 元の画像サイズ\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.75696, 0.71561, 0.63938], std=[0.19681, 0.20038, 0.24713]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return transform(image).unsqueeze(0), original_size\n",
    "\n",
    "\n",
    "# アノテーションの読み込みと前処理\n",
    "def load_and_preprocess_annotations(annotation_file):\n",
    "    \"\"\"アノテーションファイルを読み込み、前処理を行う\n",
    "\n",
    "    Args:\n",
    "        annotation_file (str): アノテーションファイルのパス\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 前処理済みのアノテーションデータ\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(annotation_file)\n",
    "\n",
    "    # boxカラムを文字列からリストに変換\n",
    "    df[\"box_in_original\"] = df[\"box_in_original\"].apply(ast.literal_eval)\n",
    "\n",
    "    # original_imageからファイル名のみを抽出\n",
    "    df[\"image_name\"] = df[\"original_image\"].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# テストデータのパスを設定\n",
    "test_image_dir = \"data/yolo_dataset_page_images_by_book/train/images\"\n",
    "test_annotation_file = \"data/processed/column_info.csv\"\n",
    "ALL_DATA_USE = False\n",
    "\n",
    "# アノテーションの読み込み\n",
    "if os.path.exists(test_annotation_file):\n",
    "    annotations_df = load_and_preprocess_annotations(test_annotation_file)\n",
    "    print(f\"Loaded {len(annotations_df)} annotations\")\n",
    "\n",
    "    # 画像ファイルの存在確認\n",
    "    image_paths = annotations_df[\"original_image\"].unique()\n",
    "    existing_images = [f for f in os.listdir(test_image_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    existing_images = [image_path for image_path in image_paths if any(image_path.endswith(b) for b in existing_images)]\n",
    "    if ALL_DATA_USE:\n",
    "        existing_images = [p for p in image_paths if os.path.exists(p)]\n",
    "    print(f\"Found {len(existing_images)} test images\")\n",
    "else:\n",
    "    print(f\"Warning: Annotation file not found at {test_annotation_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルのセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOモデルの読み込み\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model_path)\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 推論と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"IoUを計算する\n",
    "\n",
    "    Args:\n",
    "        box1: [x1, y1, x2, y2]\n",
    "        box2: [x1, y1, x2, y2]\n",
    "\n",
    "    Returns:\n",
    "        float: IoUスコア\n",
    "    \"\"\"\n",
    "    # 交差領域の座標を計算\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # 交差領域の面積を計算\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    # それぞれのボックスの面積を計算\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # IoUを計算\n",
    "    union = box1_area + box2_area - intersection\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions, ground_truth, iou_threshold=0.5):\n",
    "    \"\"\"予測結果を評価する\n",
    "\n",
    "    Args:\n",
    "        predictions: 予測された矩形のリスト [x1, y1, x2, y2, conf]\n",
    "        ground_truth: 正解の矩形のリスト [x1, y1, x2, y2]\n",
    "        iou_threshold: IoUの閾値\n",
    "\n",
    "    Returns:\n",
    "        dict: 評価指標\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = len(ground_truth)\n",
    "\n",
    "    # 各予測に対して最も近い正解を探す\n",
    "    matched_gt = set()\n",
    "    for pred in predictions:\n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "\n",
    "        for i, gt in enumerate(ground_truth):\n",
    "            if i in matched_gt:\n",
    "                continue\n",
    "\n",
    "            iou = calculate_iou(pred[:4], gt)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = i\n",
    "\n",
    "        if best_iou >= iou_threshold:\n",
    "            true_positives += 1\n",
    "            matched_gt.add(best_gt_idx)\n",
    "            false_negatives -= 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    # 評価指標の計算\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "    }\n",
    "\n",
    "\n",
    "# テスト画像に対して推論と評価を実行\n",
    "results = []\n",
    "metrics = []\n",
    "\n",
    "for image_path in tqdm(existing_images, desc=\"Testing\"):\n",
    "    image_name = os.path.basename(image_path)\n",
    "\n",
    "    # 推論\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_path)[0]\n",
    "\n",
    "    # 予測結果の取得\n",
    "    pred_boxes = predictions.boxes.data.cpu().numpy()\n",
    "\n",
    "    # グラウンドトゥルースの取得\n",
    "    gt_boxes = np.array(list(annotations_df[annotations_df[\"image_name\"] == image_name][\"box_in_original\"]))\n",
    "\n",
    "    # 評価\n",
    "    metric = evaluate_predictions(pred_boxes, gt_boxes)\n",
    "    metrics.append(metric)\n",
    "\n",
    "    # 結果を保存\n",
    "    results.append(\n",
    "        {\n",
    "            \"image_name\": image_name,\n",
    "            \"image_path\": image_path,\n",
    "            \"predictions\": pred_boxes,\n",
    "            \"ground_truth\": gt_boxes,\n",
    "            \"metrics\": metric,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 全体の評価指標を計算\n",
    "overall_metrics = {\n",
    "    \"precision\": np.mean([m[\"precision\"] for m in metrics]),\n",
    "    \"recall\": np.mean([m[\"recall\"] for m in metrics]),\n",
    "    \"f1\": np.mean([m[\"f1\"] for m in metrics]),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "for k, v in overall_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Overall Metrics:\n",
    "precision: 0.8727\n",
    "recall: 0.8965\n",
    "f1: 0.8762\n",
    "\n",
    "Val Overall Metrics:\n",
    "precision: 0.8571\n",
    "recall: 0.9578\n",
    "f1: 0.8977\n",
    "\n",
    "Test Overall Metrics:\n",
    "precision: 0.8539\n",
    "recall: 0.9594\n",
    "f1: 0.8962\n",
    "\n",
    "No_use Overall Metrics:\n",
    "precision: 0.8310\n",
    "recall: 0.8946\n",
    "f1: 0.8485\n",
    "\n",
    "All Overall Metrics:\n",
    "precision: 0.8602\n",
    "recall: 0.9056\n",
    "f1: 0.8729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(result):\n",
    "    \"\"\"検出結果を可視化する\n",
    "\n",
    "    Args:\n",
    "        result: 結果辞書\n",
    "    \"\"\"\n",
    "    image = Image.open(result[\"image_path\"])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # 予測結果の描画（赤）\n",
    "    for box in result[\"predictions\"]:\n",
    "        x1, y1, x2, y2, conf, _ = box\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color=\"red\", linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(x1, y1 - 5, f\"{conf:.2f}\", color=\"red\")\n",
    "\n",
    "    # 正解の描画（緑）\n",
    "    for box in result[\"ground_truth\"]:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color=\"green\", linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Image: {result['image_name']}\\nF1: {result['metrics']['f1']:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 最良と最悪のケースを可視化\n",
    "sorted_results = sorted(results, key=lambda x: x[\"metrics\"][\"f1\"], reverse=True)\n",
    "\n",
    "print(\"Best Case:\")\n",
    "best_case = sorted_results[3]\n",
    "visualize_results(best_case)\n",
    "\n",
    "print(\"\\nWorst Case:\")\n",
    "worst_case = sorted_results[-1]\n",
    "visualize_results(worst_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. エラー分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1スコアの分布を可視化\n",
    "f1_scores = [r[\"metrics\"][\"f1\"] for r in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(f1_scores, bins=20)\n",
    "plt.title(\"Distribution of F1 Scores\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 困難なケースの分析\n",
    "difficult_cases = [r for r in results if r[\"metrics\"][\"f1\"] < 0.5]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (F1 < 0.5)\")\n",
    "\n",
    "difficult_cases = [r for r in results if  0.5 < r[\"metrics\"][\"f1\"] < 0.6]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0.5 < F1 < 0.6)\")\n",
    "\n",
    "difficult_cases = [r for r in results if 0.6 < r[\"metrics\"][\"f1\"] < 0.7]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0.6 < F1 < 0.7)\")\n",
    "\n",
    "difficult_cases = [r for r in results if 0.7 < r[\"metrics\"][\"f1\"] < 0.8]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0.7 < F1 < 0.8)\")\n",
    "\n",
    "difficult_cases = [r for r in results if 0.8 < r[\"metrics\"][\"f1\"] < 0.9]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0.8 < F1 < 0.9)\")\n",
    "\n",
    "difficult_cases = [r for r in results if 0.9 < r[\"metrics\"][\"f1\"] < 1.0]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0.9 < F1 < 1.0)\")\n",
    "\n",
    "difficult_cases = [r for r in results if r[\"metrics\"][\"f1\"] == 1.0]\n",
    "print(f\"\\nFound {len(difficult_cases)} perfect cases (F1 = 1.0)\")\n",
    "\n",
    "difficult_cases = [r for r in results if 0 <= r[\"metrics\"][\"f1\"] <= 1.0]\n",
    "print(f\"\\nFound {len(difficult_cases)} difficult cases (0 <= F1 <= 1.0)\")\n",
    "\n",
    "if difficult_cases:\n",
    "    print(\"\\nAnalyzing a sample of difficult cases:\")\n",
    "    for case in difficult_cases[:5]:\n",
    "        print(f\"\\nImage: {case['image_name']}\")\n",
    "        print(f\"Metrics: {case['metrics']}\")\n",
    "        visualize_results(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1スコアが1.0かそれ以外かでcsvファイルに分けて保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_by_image_paths(data_list, column_info_csv_path, matched_output_path, unmatched_output_path):\n",
    "    \"\"\"\n",
    "    リスト内の辞書からimage_pathを取得し、指定されたCSVファイルのoriginal_image列と比較して、\n",
    "    一致する行と一致しない行を別々のCSVファイルに保存します。\n",
    "\n",
    "    Args:\n",
    "        data_list (list): 各要素が辞書で、'image_path'キーを持つリスト。\n",
    "                          例: [{'image_path': 'path/to/img1.jpg', ...}, ...]\n",
    "        column_info_csv_path (str): 比較対象のCSVファイルのパス (例: 'data/processed/column_info.csv')。\n",
    "                                    このCSVには 'original_image' という列が含まれている必要があります。\n",
    "        matched_output_path (str): 一致した行を保存するCSVファイルのパス。\n",
    "        unmatched_output_path (str): 一致しなかった行を保存するCSVファイルのパス。\n",
    "\n",
    "    Returns:\n",
    "        bool: 処理が正常に完了した場合はTrue、エラーが発生した場合はFalse。\n",
    "    \"\"\"\n",
    "    print(\"処理を開始します...\")\n",
    "\n",
    "    # 1. data_listからimage_pathのセットを作成\n",
    "    try:\n",
    "        image_paths_in_list = {item['image_path'] for item in data_list if 'image_path' in item}\n",
    "        if not image_paths_in_list:\n",
    "            print(\"警告: data_listに有効な 'image_path' が見つかりませんでした。\")\n",
    "            # 空でも処理は続行可能だが、結果はunmatchedのみになる\n",
    "        print(f\"入力リストから {len(image_paths_in_list)} 個の一意なimage_pathを取得しました。\")\n",
    "    except TypeError as e:\n",
    "        print(f\"エラー: data_listの形式が正しくない可能性があります: {e}\")\n",
    "        return False\n",
    "    except KeyError as e:\n",
    "         print(f\"エラー: data_list内の辞書に 'image_path' キーが存在しません: {e}\")\n",
    "         return False\n",
    "\n",
    "    # 2. column_info.csvを読み込む\n",
    "    try:\n",
    "        df_column_info = pd.read_csv(column_info_csv_path)\n",
    "        print(f\"'{column_info_csv_path}' を読み込みました。({len(df_column_info)}行)\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"エラー: CSVファイルが見つかりません: {column_info_csv_path}\")\n",
    "        return False\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"エラー: CSVファイルが空です: {column_info_csv_path}\")\n",
    "        # 空のファイルに対して処理を進めることもできるが、ここではエラーとする\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: CSVファイルの読み込み中にエラーが発生しました ({column_info_csv_path}): {e}\")\n",
    "        return False\n",
    "\n",
    "    # 3. 'original_image' 列が存在するか確認\n",
    "    if 'original_image' not in df_column_info.columns:\n",
    "        print(f\"エラー: CSVファイルに 'original_image' 列が見つかりません: {column_info_csv_path}\")\n",
    "        return False\n",
    "\n",
    "    # 4. 一致する行と一致しない行をフィルタリング\n",
    "    try:\n",
    "        # 'original_image' 列の値が image_paths_in_list に含まれるかどうかでブールマスクを作成\n",
    "        is_matched = df_column_info['original_image'].isin(image_paths_in_list)\n",
    "\n",
    "        # マスクを使ってデータフレームを分割\n",
    "        df_matched = df_column_info[is_matched]\n",
    "        df_unmatched = df_column_info[~is_matched] # '~' はブール否定\n",
    "\n",
    "        print(f\"一致した行数: {len(df_matched)}\")\n",
    "        print(f\"一致しなかった行数: {len(df_unmatched)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: データフレームのフィルタリング中にエラーが発生しました: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 5. 結果をCSVファイルに保存\n",
    "    try:\n",
    "        # 出力ディレクトリが存在しない場合は作成\n",
    "        os.makedirs(os.path.dirname(matched_output_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(unmatched_output_path), exist_ok=True)\n",
    "\n",
    "        # index=False でデータフレームのインデックスをCSVに書き出さないようにする\n",
    "        df_matched.to_csv(matched_output_path, index=False)\n",
    "        print(f\"一致した行を '{matched_output_path}' に保存しました。\")\n",
    "\n",
    "        df_unmatched.to_csv(unmatched_output_path, index=False)\n",
    "        print(f\"一致しなかった行を '{unmatched_output_path}' に保存しました。\")\n",
    "\n",
    "        print(\"処理が正常に完了しました。\")\n",
    "        return True\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"エラー: CSVファイルへの書き込み中にエラーが発生しました: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: 結果の保存中に予期せぬエラーが発生しました: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1スコアが1.0以下のケースをcsvに保存\n",
    "matched_output_path = \"data/processed/matched_results.csv\"\n",
    "unmatched_output_path = \"data/processed/unmatched_results.csv\"\n",
    "below_1_results = [r for r in results if r[\"metrics\"][\"f1\"] < 1.0]\n",
    "print(f\"\\nFound {len(below_1_results)} cases with F1 < 1.0\")\n",
    "split_csv_by_image_paths(\n",
    "    below_1_results,\n",
    "    test_annotation_file,\n",
    "    matched_output_path,\n",
    "    unmatched_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_1_cases = [r for r in results if r[\"metrics\"][\"f1\"] == 1.0]\n",
    "# matched_output_path = \"data/processed/f1_score_1.0.csv\"\n",
    "# unmatched_output_path = \"data/processed/f1_score_below_1.0.csv\"\n",
    "# print(f\"num of f1 score 1.0 images: {len(f1_1_cases)}\")\n",
    "# split_csv_by_image_paths(f1_1_cases, test_annotation_file, matched_output_path, unmatched_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
